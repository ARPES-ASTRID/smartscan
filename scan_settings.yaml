TCP:
  host: localhost
  port: 54333
  buffer_size: 8388608 # 8MB
  timeout: 10 # seconds

logging:
  level: INFO
  directory: null
  formatter: '%(asctime)s - %(name)s - %(levelname)s | %(message)s'

paths:
  data: './data'

scanning:
  max_points: 499 # 0 for unlimited
  duration: 1_000_000
  train_at: [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]
  train_every: 0 # 0 for no training
  normalize_values: training # one of init, training, always, fixed or never
  fixed_normalization: [1.0, 1.0] # normalization factors for each task

preprocessing: 
# list of preprocessing functions to apply to the data. 
# Functions are chained in the order they are listed.
  # reshape:
  #   function: reshape 
  #   params: 
  #     shape: [] # parameters of the function
  roi:
    function: roi # name of the function found in gp/preprocessing.py
    params: 
      x_lim: [0,-1] # parameters of the function  
      y_lim: [0,-1]

tasks: # list of tasks to which to reduce the data
  mean: # name of the task found in gp/tasks.py
    function: mean # name of the function
    params: null # parameters of the function
  laplace_filter:
    function: laplace_filter
    params:
      sigma: 5
      norm: False
  # signal_to_bg:
  #   function: signal_to_bg
  #   params: null

acquisition_function:
  function: acquisition_function_nd # name of the function found in gp/acquisition_functions.py
  params:
    a: 3.0 # exploration vs exploitation, i.e. variance weight
    weights: null
    norm: 1 # normalization factor for acquisition function
    c: 0 # covariance weight

cost_function:
  function: manhattan_cost_function # name of the function found in gp/cost_functions.py
  params: 
    speed: 300 # um/s
    dwell_time: 1 # seconds
    dead_time: 0.6 # seconds
    weight: 0.1 # weight of the cost function

gp:
  optimizer:
    output_space_dimension: 1 # just leave it at 1

  fvgp:
    init_hyperparameters: [1_000_000, 100, 100, 100]
    compute_device: cpu # cpu or cuda:0
    gp_kernel_function: null
    gp_mean_function: null
    use_inv: false
    ram_economy: true # shouldnt really do anything without use_inv

  training:
    hyperparameter_bounds: [
      [1_000_000, 1_000_000_000],
      [10, 1000],
      [10, 1000],
      [10, 1000]
    ]
    pop_size: 20 # population size for global optimization
    max_iter: 2 # maximum number of iterations for global optimization
    tolerance: 0.000001 # tolerance for global optimization

  ask:
    n: 1 # number of points to ask per iteration
    bounds: null # bounds of the input space
    method: global # global or local
    pop_size: 20 # population size for global optimization
    max_iter: 10 # maximum number of iterations for global optimization
    tol: 0.000001 # tolerance for global optimization
    # x0: all # positions where to evaluate the acquisition function

